{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99560719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f21d869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titles_Relabeled_2 = pd.read_csv('Titles_English_Relabeled_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8431400",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titles_Relabeled_2 = Titles_Relabeled_2.drop('Unnamed: 0', axis=1)\n",
    "Titles_Relabeled_2['EAN'] = Titles_Relabeled_2['EAN'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0dfbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300359, 3830)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=1000, ngram_range=(1,2), stop_words='english')\n",
    "features = tfidf.fit_transform(Titles_Relabeled_2['Annotation Text']).toarray()\n",
    "labels = Titles_Relabeled_2.Category\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40ee8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titles_train, Titles_test = train_test_split(Titles_Relabeled_2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f21dc7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pupnsuds90\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 74.00%\n",
      "F1 score: 0.76\n",
      "Recall: 0.74\n",
      "                    EAN                                              Title  \\\n",
      "272607  9780000000000.0  Dancing Bear                                  ...   \n",
      "40303   9780000000000.0  Life of General Ulysses S. Grant: Containing a...   \n",
      "172631  9780000000000.0  Adam's Illustrated Guide to Rye (with map): Wi...   \n",
      "286961  9780000000000.0  Angela's Letter                               ...   \n",
      "191935  9780000000000.0  Memoirs of a Professional Lady Nurse          ...   \n",
      "...                 ...                                                ...   \n",
      "182491  9780000000000.0  Feeling Special                               ...   \n",
      "23941   9780000000000.0  My Father's People                            ...   \n",
      "2172    9780000000000.0  Every Kid's Guide to Coping with Childhood Tra...   \n",
      "114632  9780000000000.0  Nevermore...                                  ...   \n",
      "153901  9780000000000.0  Sea Pictures, Op.37: Vocal score (Urtext)     ...   \n",
      "\n",
      "                                          Annotation Text MJR BISAC  \\\n",
      "272607  'You don't want to mind about any of this, ' s...       BIO   \n",
      "40303   \"General Grant is emphatically a man, not of w...       LCO   \n",
      "172631  This work has been selected by scholars as bei...       HIS   \n",
      "286961  They say one never forgets his or her first lo...       FIC   \n",
      "191935  This work has been selected by scholars as bei...       HIS   \n",
      "...                                                   ...       ...   \n",
      "182491  Very Vanilla Bean ice cream doesn't feel very ...       JUV   \n",
      "23941   'Who am I? What are my roots?' These are quest...       REF   \n",
      "2172    Every Kid's Guide to Coping With Childhood Tra...       EDU   \n",
      "114632  Victoria Dahl is a self-made multi-billionaire...       FIC   \n",
      "153901  Composed for the Norfolk and Norwich Festival,...       MUS   \n",
      "\n",
      "        Predicted Category  Confidence Score  \n",
      "272607                   0          0.655571  \n",
      "40303                    1          0.799374  \n",
      "172631                   1          0.995921  \n",
      "286961                   0          0.773413  \n",
      "191935                   1          0.995921  \n",
      "...                    ...               ...  \n",
      "182491                   0          0.880694  \n",
      "23941                    1          0.546399  \n",
      "2172                     0          0.689451  \n",
      "114632                   0          0.772974  \n",
      "153901                   1          0.954359  \n",
      "\n",
      "[75090 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state=42)\n",
    "\n",
    "# Initialize the MaxAbsScaler\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "# Fit on the training data and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Just transform the test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the Logistic Regression model on the scaled data\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the predicted labels and probabilities on the scaled test data\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "y_pred_proba = logreg.predict_proba(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Model accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {f1:.2f}')\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall:.2f}')\n",
    "\n",
    "# Create a dataframe with the predicted labels and maximum probabilities (confidence scores)\n",
    "results_df = pd.DataFrame({\n",
    "    'Predicted Category': y_pred,\n",
    "    'Confidence Score': np.max(y_pred_proba, axis=1)\n",
    "}, index=Titles_test.index)  # use the same indices as in Titles_test\n",
    "\n",
    "# Add the 'Annotation Text' column to the results\n",
    "results_df = Titles_test[['EAN', 'Title', 'Annotation Text', 'MJR BISAC']].join(results_df)\n",
    "\n",
    "# Print the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11fa417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
